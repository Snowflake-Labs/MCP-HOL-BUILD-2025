{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ce3c0b",
   "metadata": {},
   "source": [
    "# Build Agent-Powered Workflows Using Snowflake Cortex AI and Managed MCP Servers\n",
    "\n",
    "This notebook demonstrates how to build a LangGraph agent using MCP tools, and how to use AI observability to evaluate and improve the tool descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a52dae9",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We'll build a health research agent that uses MCP tools to query:\n",
    "- PubMed for medical literature\n",
    "- Clinical trials databases for trial information\n",
    "\n",
    "TruLens will automatically trace all tool calls, showing:\n",
    "- Which MCP tools are being called\n",
    "- Input arguments and outputs\n",
    "- Execution time and errors\n",
    "- Full conversation flow in the dashboard\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, start by updating your account settings to create an allow-all network policy, and enable cross-region inference for calling `claude-sonnet-4-5`. You can do this by copying and running `alter_account_settings.sql` in a Snowflake SQL worksheet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b01a7",
   "metadata": {},
   "source": [
    "## Install python packages in your environment\n",
    "\n",
    "install the following libraries:\n",
    "\n",
    "- trulens-connectors-snowflake\n",
    "- trulens-core\n",
    "- trulens-providers-cortex\n",
    "- trulens-apps-langgraph\n",
    "- langchain-openai\n",
    "- langchain-mcp-adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trulens-connectors-snowflake trulens-core trulens-providers-cortex trulens-apps-langgraph 'langchain-openai==0.3.30' langchain-mcp-adapters -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa2d1b8",
   "metadata": {},
   "source": [
    "## Get AI-ready data\n",
    "\n",
    "Then, in your snowflake accoount access the Clinical Trials and PubMed listings and load them to your account following the below steps:\n",
    "\n",
    "1. Sign in to Snowsight.\n",
    "\n",
    "2. In the navigation menu, select Marketplace.\n",
    "\n",
    "3. Search or browse to the listing you want to access.\n",
    "\n",
    "4. Select Get to access a listing already available in your region. A dialog opens with details about the listing. If you have to request the listing to be replicated to your region, select Request.\n",
    "\n",
    "5. (Optional) Specify a database name for the data in the listing.\n",
    "\n",
    "6. (Optional) Add roles to grant access to the database created from the listing.\n",
    "\n",
    "7. Select Get.\n",
    "\n",
    "8. In the confirmation dialog that appears, select Open to open a Snowsight worksheet with an example query in a new tab, or select Done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ae1d4",
   "metadata": {},
   "source": [
    "## Create MCP Server in Snowflake\n",
    "\n",
    "Copy `create_mcp_server.sql` to a Snowflake worksheet and run. This will create an MCP server with the two Cortex Knowledge Extensions created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "# Configure API keys and MCP server connection\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "os.environ[\"SNOWFLAKE_PAT\"] = \"ey...\"\n",
    "os.environ[\"SNOWFLAKE_ACCOUNT\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_USER\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_MCP_SERVER_URL\"] = \"https://<account-id>.snowflakecomputing.com/api/v2/databases/HEALTH_DB/schemas/PUBLIC/mcp-servers/HEALTH_MCP_SERVER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5535095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "import os\n",
    "\n",
    "snowflake_connection_parameters = {\n",
    "    \"account\": os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PAT\"),\n",
    "    \"warehouse\": \"MCP_WH\",\n",
    "    \"database\": \"HEALTH_DB\",\n",
    "    \"schema\": \"PUBLIC\",\n",
    "}\n",
    "\n",
    "snowpark_session = Session.builder.configs(\n",
    "    snowflake_connection_parameters\n",
    ").create()\n",
    "\n",
    "snowpark_session.sql(\"USE WAREHOUSE MCP_WH\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0933e60",
   "metadata": {},
   "source": [
    "## Create MCP Client and Get Tools\n",
    "\n",
    "We'll use the `MultiServerMCPClient` from `langchain_mcp_adapters` to connect to the health research MCP server and retrieve available tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import START\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "client = MultiServerMCPClient({\n",
    "    \"health_research\": {\n",
    "        \"transport\": \"streamable_http\",\n",
    "        \"url\": os.environ[\"SNOWFLAKE_MCP_SERVER_URL\"],\n",
    "        \"headers\": {\"Authorization\": f\"Bearer {os.environ['SNOWFLAKE_PAT']}\",\n",
    "        },\n",
    "    }\n",
    "})\n",
    "tools = await client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abcaa0",
   "metadata": {},
   "source": [
    "## Build the LangGraph Agent\n",
    "\n",
    "Now we'll create a LangGraph application with:\n",
    "1. **call_model** node - The LLM that decides which tools to use\n",
    "2. **tools** node - Executes the selected MCP tools\n",
    "3. **tools_condition** - Routes between the model and tools\n",
    "\n",
    "The graph will loop between the model and tools until the agent has enough information to answer the question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa92cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Define the call_model function\n",
    "async def call_model(state: MessagesState):\n",
    "    response = await model.bind_tools(tools).ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Create the StateGraph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(call_model)\n",
    "builder.add_node(ToolNode(tools))\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\n",
    "    \"call_model\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"call_model\")\n",
    "graph = builder.compile()\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, graph):\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        self.graph = graph\n",
    "\n",
    "    async def ainvoke(self, messages):\n",
    "        \"\"\"Async version\"\"\"\n",
    "        return await self.graph.ainvoke({\"messages\": messages})\n",
    "    \n",
    "    def invoke(self, messages):\n",
    "        \"\"\"Sync wrapper around async method\"\"\"\n",
    "        return asyncio.run(self.ainvoke(messages))\n",
    "\n",
    "agent = Agent(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77208a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\"What is the primary indicator for the drug Xeljanz?\")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8dd2b",
   "metadata": {},
   "source": [
    "## Initialize TruLens Session\n",
    "\n",
    "Set up TruLens to store traces and evaluations in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b1a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "\n",
    "sf_connector = SnowflakeConnector(snowpark_session=snowpark_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c7315",
   "metadata": {},
   "source": [
    "## Create Tool Selection Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2676fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.feedback.custom_metric import MetricConfig\n",
    "from trulens.core.feedback.selector import Selector\n",
    "from trulens.providers.cortex import Cortex\n",
    "\n",
    "provider = Cortex(\n",
    "    model_engine=\"claude-sonnet-4-5\", snowpark_session=snowpark_session\n",
    ")\n",
    "\n",
    "f_tool_selection = MetricConfig(\n",
    "    metric_name = \"Tool Selection\",\n",
    "    metric_implementation = provider.tool_selection_with_cot_reasons,\n",
    "    selectors={\n",
    "        \"trace\": Selector(trace_level=True),\n",
    "    },\n",
    ")\n",
    "\n",
    "f_tool_calling = MetricConfig(\n",
    "    metric_name = \"Tool Calling\",\n",
    "    metric_implementation = provider.tool_calling_with_cot_reasons,\n",
    "    selectors={\n",
    "        \"trace\": Selector(trace_level=True),\n",
    "    },\n",
    ")\n",
    "\n",
    "metrics_to_compute = [\n",
    "    f_tool_selection,\n",
    "    f_tool_calling,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c060a5",
   "metadata": {},
   "source": [
    "## Record Agent Execution with TruLens\n",
    "\n",
    "Wrap the LangGraph application with `TruGraph` to automatically instrument and trace all executions.\n",
    "\n",
    "TruLens will capture:\n",
    "- Each node execution in the graph\n",
    "- MCP tool calls with their names (e.g., `pubmed_search`, `clinical_trials_search`)\n",
    "- Input/output states at each step\n",
    "- LLM generation calls\n",
    "- Tool routing decisions\n",
    "\n",
    "The trace will show the complete flow of the agent's reasoning and tool usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17deb326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.langgraph import TruGraph\n",
    "\n",
    "tru_app = TruGraph(\n",
    "    app=agent,\n",
    "    app_name=\"healthcare_research_assistant_4\",\n",
    "    app_version=\"base\",\n",
    "    main_method=agent.invoke,\n",
    "    connector=sf_connector,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "queries = [\"How do semaglutide and tirzepatide compare in published studies, and what head-to-head clinical trials are recruiting patients?\",\n",
    "\"What are the latest clinical trials for Alzheimer's disease?\",\n",
    "\"What is the primary indicator for the drug Xeljanz?\"]\n",
    "\n",
    "queries_df = pd.DataFrame(queries, columns=[\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6b840",
   "metadata": {},
   "source": [
    "## Configure Batched Run\n",
    "\n",
    "Set up a **batched run** configuration to evaluate multiple queries at once. This enables:\n",
    "- Parallel execution of multiple agent invocations\n",
    "- Efficient batch processing using Snowflake compute\n",
    "- Organized tracking of related evaluations\n",
    "- Dataset management for reproducible experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from trulens.core.run import Run\n",
    "from trulens.core.run import RunConfig\n",
    "\n",
    "run_name = f\"health_queries_run_{uuid.uuid4()}\"\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=run_name,\n",
    "    dataset_name=\"health_research_queries\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    dataset_spec={\"RECORD_ROOT.INPUT\": \"query\"},\n",
    ")\n",
    "\n",
    "run: Run = tru_app.add_run(run_config=run_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0738c",
   "metadata": {},
   "source": [
    "## Execute Batched Run\n",
    "\n",
    "Start the batched run to invoke the agent on all queries in the dataset. Each invocation will be traced and stored in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ca933",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.start(input_df=queries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae8f57",
   "metadata": {},
   "source": [
    "## Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000020f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while run.get_status() != \"INVOCATION_COMPLETED\":\n",
    "    print(f\"Status: {run.get_status()}\")\n",
    "    time.sleep(3)\n",
    "\n",
    "print(\"Invocations complete, computing metrics...\")\n",
    "run.compute_metrics(metrics_to_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ddede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Agent V2: Improved Tool Descriptions\n",
    "\n",
    "The base agent had two critical issues identified through TruLens evaluation:\n",
    "\n",
    "## Problems with Base Version\n",
    "\n",
    "**1. Poor Tool Selection (Score: Low)**\n",
    "- Agent didn't use tools for factual medical queries (e.g., \"What is Xeljanz indicated for?\")\n",
    "- Relied on internal knowledge instead of authoritative sources\n",
    "- Missed opportunities to verify medical information\n",
    "\n",
    "**2. Tool Calling Errors (Multiple Failures)**\n",
    "- Agent repeatedly tried to specify columns (`title`, `abstract`, `brief_description`, `disease_stage`)\n",
    "- These columns aren't indexed in Cortex Search, causing errors\n",
    "- No adaptation after errors - kept making the same mistakes\n",
    "- Example errors: `\"Column abstract was not indexed in this Cortex Search Service\"`\n",
    "\n",
    "## V2 Solution: Enhanced Tool Descriptions\n",
    "\n",
    "The V2 MCP server (`health_mcp_server_v2`) fixes these issues with improved tool descriptions:\n",
    "\n",
    "### Fix 1: Mandate Tool Usage\n",
    "- Tools marked as **\"AUTHORITATIVE\"** sources\n",
    "- Explicit **\"MANDATORY USE for\"** statements for specific query types\n",
    "- Lists exact use cases: drug indications, efficacy data, safety profiles, etc.\n",
    "\n",
    "### Fix 2: Prevent Column Specification Errors\n",
    "- Clear instruction: **\"Only provide 'query' parameter\"**\n",
    "- Agent will not specify columns to search that are not available\n",
    "\n",
    "### Expected Improvements\n",
    "- ✅ Higher Tool Selection scores (agent uses tools consistently)\n",
    "- ✅ Higher Tool Calling scores (no more column errors)\n",
    "\n",
    "## Setup Required\n",
    "\n",
    "Before running V2 cells, create the improved MCP server:\n",
    "```sql\n",
    "-- Run create_mcp_server_v2.sql in Snowflake\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_section",
   "metadata": {},
   "source": [
    "## Implementing Agent V2\n",
    "\n",
    "Now let's build and test the V2 agent with improved tool descriptions.\n",
    "\n",
    "**Prerequisites:** Ensure you've run `create_mcp_server_v2.sql` in Snowflake to create the `health_mcp_server_v2` MCP server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_client",
   "metadata": {},
   "source": [
    "## Create V2 Client with Improved MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_client_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the V2 MCP server\n",
    "os.environ[\"SNOWFLAKE_MCP_SERVER_V2_URL\"] = os.environ[\"SNOWFLAKE_MCP_SERVER_URL\"].replace(\n",
    "    \"health_mcp_server\", \"health_mcp_server_v2\"\n",
    ")\n",
    "\n",
    "client_v2 = MultiServerMCPClient({\n",
    "    \"health_research_v2\": {\n",
    "        \"transport\": \"streamable_http\",\n",
    "        \"url\": os.environ[\"SNOWFLAKE_MCP_SERVER_V2_URL\"],\n",
    "        \"headers\": {\"Authorization\": f\"Bearer {os.environ['SNOWFLAKE_PAT']}\"},\n",
    "    }\n",
    "})\n",
    "tools_v2 = await client_v2.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_agent",
   "metadata": {},
   "source": [
    "## Build Agent V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_agent_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with V2 tools\n",
    "model_v2 = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "async def call_model_v2(state: MessagesState):\n",
    "    response = await model_v2.bind_tools(tools_v2).ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "builder_v2 = StateGraph(MessagesState)\n",
    "builder_v2.add_node(call_model_v2)\n",
    "builder_v2.add_node(ToolNode(tools_v2))\n",
    "builder_v2.add_edge(START, \"call_model_v2\")\n",
    "builder_v2.add_conditional_edges(\"call_model_v2\", tools_condition)\n",
    "builder_v2.add_edge(\"tools\", \"call_model_v2\")\n",
    "graph_v2 = builder_v2.compile()\n",
    "\n",
    "agent_v2 = Agent(graph_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_trugraph",
   "metadata": {},
   "source": [
    "## Wrap V2 Agent with TruGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_trugraph_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_app_v2 = TruGraph(\n",
    "    app=agent_v2,\n",
    "    app_name=\"healthcare_research_assistant-build-hol\",\n",
    "    app_version=\"v2_improved_descriptions\",\n",
    "    main_method=agent_v2.invoke,\n",
    "    connector=sf_connector,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_run",
   "metadata": {},
   "source": [
    "## Run V2 Agent on Same Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_run_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_v2 = f\"health_queries_run_v2_{uuid.uuid4()}\"\n",
    "\n",
    "run_config_v2 = RunConfig(\n",
    "    run_name=run_name_v2,\n",
    "    dataset_name=\"health_research_queries\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    dataset_spec={\"RECORD_ROOT.INPUT\": \"query\"},\n",
    ")\n",
    "\n",
    "run_v2: Run = tru_app_v2.add_run(run_config=run_config_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_start",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_v2.start(input_df=queries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_metrics",
   "metadata": {},
   "source": [
    "## Compute Metrics for V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1aa959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_metrics_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "while run_v2.get_status() != \"INVOCATION_COMPLETED\":\n",
    "    print(f\"V2 Status: {run_v2.get_status()}\")\n",
    "    time.sleep(3)\n",
    "\n",
    "print(\"V2 invocations complete, computing metrics...\")\n",
    "run_v2.compute_metrics(metrics_to_compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499bbaef",
   "metadata": {},
   "source": [
    "## Compare results\n",
    "\n",
    "By visiting the Comparison tab for Health Research Agent, we can compare how the agent performs with both versions of our MCP Server (before and after the tool description change).\n",
    "\n",
    "![agent_version_comparison.png](agent_version_comparison.png)\n",
    "\n",
    "By updating the tool descritions to mandate tool usage for specified use cases and specifying the search parameter, our agent is able to resolve the tool selection and tool calling failures from the first version of the agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_mcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
