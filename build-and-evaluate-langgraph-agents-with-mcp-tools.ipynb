{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03ce3c0b",
   "metadata": {},
   "source": [
    "# Build Agent-Powered Workflows Using Snowflake Cortex AI and Managed MCP Servers\n",
    "\n",
    "This notebook demonstrates how to build a LangGraph agent using MCP tools, and how to use AI observability to evaluate and improve the tool descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a52dae9",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "We'll build a health research agent that uses MCP tools to query:\n",
    "- PubMed for medical literature\n",
    "- Clinical trials databases for trial information\n",
    "\n",
    "TruLens will automatically trace all tool calls, showing:\n",
    "- Which MCP tools are being called\n",
    "- Input arguments and outputs\n",
    "- Execution time and errors\n",
    "- Full conversation flow in the dashboard\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, start by updating your account settings to create an allow-all network policy, and enable cross-region inference for calling `claude-sonnet-4-5`. You can do this by copying and running [`alter_account_settings.sql`](./alter_account_settings.sql) in a Snowflake SQL worksheet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2b01a7",
   "metadata": {},
   "source": [
    "## Install python packages in your environment\n",
    "\n",
    "install the following libraries:\n",
    "\n",
    "- trulens-connectors-snowflake\n",
    "- trulens-core\n",
    "- trulens-providers-cortex\n",
    "- trulens-apps-langgraph\n",
    "- langchain-openai OR langchain-snowflake\n",
    "- langchain-mcp-adapters\n",
    "\n",
    "ðŸš¨ðŸš¨ If you are using `langchain-snowflake` for calling LLMs, you will need to use python versions <3.12, >=3.9. Please make sure your python environment is using a supported python version, otherwise `langchain-snowflake` will not be able to be installed. ðŸš¨ðŸš¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4399ecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install trulens-connectors-snowflake trulens-core trulens-providers-cortex trulens-apps-langgraph 'langchain-openai==0.3.30' langchain-mcp-adapters 'langchain-snowflake==0.2.2' -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa2d1b8",
   "metadata": {},
   "source": [
    "## Get AI-ready data\n",
    "\n",
    "In this step, you will get access to AI-ready data from ClinicalTrials.gov and Pubmed Central via [Cortex Knowledge Extensions](https://docs.snowflake.com/en/user-guide/snowflake-cortex/cortex-knowledge-extensions/cke-overview), prre-built Cortex Search Services available on the Snowflake marketplace.\n",
    "\n",
    "1. Open the marketplace listing for the [Clinical Trials Research Database](https://app.snowflake.com/marketplace/listing/GZSTZ67BY9ORD/snowflake-clinical-trials-research-database)\n",
    "\n",
    "2. Select Get to access the listing\n",
    "\n",
    "3. Add the public role to grant access to the database created from the listing.\n",
    "\n",
    "4. Select Get.\n",
    "\n",
    "5. In the confirmation dialog that appears, select Open to open a Snowsight worksheet with an example query in a new tab, or select Done.\n",
    "\n",
    "6. Repeat steps 1-5 with the listing for the [PubMed Biomedical Research Corpus](https://app.snowflake.com/marketplace/listing/GZSTZ67BY9OQW/snowflake-pubmed-biomedical-research-corpus?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718ae1d4",
   "metadata": {},
   "source": [
    "## Create MCP Server in Snowflake\n",
    "\n",
    "Copy [`create_mcp_server.sql`](./create_mcp_server.sql) to a Snowflake worksheet and run. This will create an MCP server with the two Cortex Knowledge Extensions created in the previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a8b3f",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#ffe6e6; padding:20px; border-width:4px; border-color:#e07070; border-style:double; border-radius:8px; color:#a00000; font-weight:bold;\">\n",
    "\n",
    "## ðŸ”‘ API Key Configuration: OpenAI (Optional)\n",
    "    \n",
    "ðŸš¨ **CRITICAL NOTE:** If you'd like to run the agent with **only Snowflake Cortex LLMs**, you can leave the `OPENAI_API_KEY` commented out. You will choose the Snowflake Cortex model option later in the notebook.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ed6460",
   "metadata": {},
   "source": [
    "## Add your Snowflake (and optionally OpenAI) credentials below.\n",
    "\n",
    "To retrieve your Snowflake credentials, follolw the steps below:\n",
    "\n",
    "1. Get your Programmatic Access Token (PAT) [here](https://app.snowflake.com/_deeplink/settings/authentication)\n",
    "2. Click on your user profile in the bottom left\n",
    "3. Choose Connect a tool to Snowflake\n",
    "4. Copy the value for your Account identifier and paste it in the placeholders below both in SNOWFLAKE_ACCOUNT and in place of <account-id> in the SNOWFLAKE_MCP_SERVER_URL.\n",
    "5. Copy the value for Login name and paste it in the SNOWFLAKE_USER placeholder.\n",
    "\n",
    "If you choose to use OpenAI, you can create or retrieve an API key [here](https://platform.openai.com/api-keys)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "# Configure API keys and MCP server connection\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"sk-proj-...\"\n",
    "os.environ[\"SNOWFLAKE_PAT\"] = \"ey...\"\n",
    "os.environ[\"SNOWFLAKE_ACCOUNT\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_USER\"] = \"...\"\n",
    "os.environ[\"SNOWFLAKE_MCP_SERVER_URL\"] = \"https://<account-id>.snowflakecomputing.com/api/v2/databases/HEALTH_DB/schemas/PUBLIC/mcp-servers/HEALTH_MCP_SERVER\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5535095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "import os\n",
    "\n",
    "snowflake_connection_parameters = {\n",
    "    \"account\": os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PAT\"),\n",
    "    \"warehouse\": \"MCP_WH\",\n",
    "    \"database\": \"HEALTH_DB\",\n",
    "    \"schema\": \"PUBLIC\",\n",
    "}\n",
    "\n",
    "snowpark_session = Session.builder.configs(\n",
    "    snowflake_connection_parameters\n",
    ").create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0933e60",
   "metadata": {},
   "source": [
    "## Create MCP Client and Get Tools\n",
    "\n",
    "We'll use the `MultiServerMCPClient` from `langchain_mcp_adapters` to connect to the health research MCP server and retrieve available tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.graph import START\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "client = MultiServerMCPClient({\n",
    "    \"health_research\": {\n",
    "        \"transport\": \"streamable_http\",\n",
    "        \"url\": os.environ[\"SNOWFLAKE_MCP_SERVER_URL\"],\n",
    "        \"headers\": {\"Authorization\": f\"Bearer {os.environ['SNOWFLAKE_PAT']}\",\n",
    "        },\n",
    "    }\n",
    "})\n",
    "tools = await client.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83061a0c",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#e6f7ff; padding:15px; border-width:3px; border-color:#91d5ff; border-style:solid; border-radius:6px; **color:#003a61;**\">\n",
    "    \n",
    "### ðŸŸ¢ **Option 1: OpenAI via LangChain**\n",
    "    \n",
    "**Action:** **UNCOMMENT and RUN** the code cell below if you are using LangChain with an **OpenAI API Key** (`gpt-4o`).\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a23ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# # Initialize the LLM\n",
    "# model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1924e4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f0f8ff; padding:15px; border-width:3px; border-color:#adc6ff; border-style:solid; border-radius:6px;\">\n",
    "\n",
    "### ðŸ”µ **Option 2: Snowflake Cortex via LangChain**\n",
    "\n",
    "**Action:** **UNCOMMENT and RUN** the code cell below if you are using LangChain with **Snowflake Cortex** (`claude-4-sonnet`).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064d56ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_snowflake import ChatSnowflake\n",
    "\n",
    "# Initialize chat model\n",
    "model = ChatSnowflake(\n",
    "    session=snowpark_session, \n",
    "    model=\"claude-sonnet-4-5\", \n",
    "    temperature=0.1, \n",
    "    max_tokens=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7abcaa0",
   "metadata": {},
   "source": [
    "## Build the LangGraph Agent\n",
    "\n",
    "Now we'll create a LangGraph application with:\n",
    "1. **call_model** node - The LLM that decides which tools to use\n",
    "2. **tools** node - Executes the selected MCP tools\n",
    "3. **tools_condition** - Routes between the model and tools\n",
    "\n",
    "The graph will loop between the model and tools until the agent has enough information to answer the question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa92cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# Define the call_model function\n",
    "async def call_model(state: MessagesState):\n",
    "    response = await model.bind_tools(tools).ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# Create the StateGraph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(call_model)\n",
    "builder.add_node(ToolNode(tools))\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\n",
    "    \"call_model\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"call_model\")\n",
    "graph = builder.compile()\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, graph):\n",
    "        import nest_asyncio\n",
    "        nest_asyncio.apply()\n",
    "        self.graph = graph\n",
    "\n",
    "    async def ainvoke(self, messages):\n",
    "        \"\"\"Async version\"\"\"\n",
    "        return await self.graph.ainvoke({\"messages\": messages})\n",
    "    \n",
    "    def invoke(self, messages):\n",
    "        \"\"\"Sync wrapper around async method\"\"\"\n",
    "        return asyncio.run(self.ainvoke(messages))\n",
    "\n",
    "agent = Agent(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96deb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(agent.graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77208a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.invoke(\"What is the primary indicator for the drug Xeljanz?\")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8dd2b",
   "metadata": {},
   "source": [
    "## Initialize TruLens Session\n",
    "\n",
    "Set up TruLens to store traces and evaluations in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b1a461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "\n",
    "sf_connector = SnowflakeConnector(snowpark_session=snowpark_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8c7315",
   "metadata": {},
   "source": [
    "## Create Tool Selection Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2676fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.core.feedback.custom_metric import MetricConfig\n",
    "from trulens.core.feedback.selector import Selector\n",
    "from trulens.providers.cortex import Cortex\n",
    "\n",
    "provider = Cortex(\n",
    "    model_engine=\"claude-sonnet-4-5\", snowpark_session=snowpark_session\n",
    ")\n",
    "\n",
    "f_tool_selection = MetricConfig(\n",
    "    metric_name = \"Tool Selection\",\n",
    "    metric_implementation = provider.tool_selection_with_cot_reasons,\n",
    "    selectors={\n",
    "        \"trace\": Selector(trace_level=True),\n",
    "    },\n",
    ")\n",
    "\n",
    "f_tool_calling = MetricConfig(\n",
    "    metric_name = \"Tool Calling\",\n",
    "    metric_implementation = provider.tool_calling_with_cot_reasons,\n",
    "    selectors={\n",
    "        \"trace\": Selector(trace_level=True),\n",
    "    },\n",
    ")\n",
    "\n",
    "metrics_to_compute = [\n",
    "    f_tool_selection,\n",
    "    f_tool_calling,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c060a5",
   "metadata": {},
   "source": [
    "## Record Agent Execution with TruLens\n",
    "\n",
    "Wrap the LangGraph application with `TruGraph` to automatically instrument and trace all executions.\n",
    "\n",
    "TruLens will capture:\n",
    "- Each node execution in the graph\n",
    "- MCP tool calls with their names (e.g., `pubmed_search`, `clinical_trials_search`)\n",
    "- Input/output states at each step\n",
    "- LLM generation calls\n",
    "- Tool routing decisions\n",
    "\n",
    "The trace will show the complete flow of the agent's reasoning and tool usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17deb326",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trulens.apps.langgraph import TruGraph\n",
    "\n",
    "tru_app = TruGraph(\n",
    "    app=agent,\n",
    "    app_name=\"healthcare_research_assistant\",\n",
    "    app_version=\"base\",\n",
    "    main_method=agent.invoke,\n",
    "    connector=sf_connector,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388d31b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "queries = [\"How do semaglutide and tirzepatide compare in published studies, and what head-to-head clinical trials are recruiting patients?\",\n",
    "\"What are the latest clinical trials for Alzheimer's disease?\",\n",
    "\"What is the primary indicator for the drug Xeljanz?\"]\n",
    "\n",
    "queries_df = pd.DataFrame(queries, columns=[\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda6b840",
   "metadata": {},
   "source": [
    "## Configure Batched Run\n",
    "\n",
    "Set up a **batched run** configuration of our dataset. This enables:\n",
    "- Execution of multiple agent invocations\n",
    "- Organized tracking of related evaluations\n",
    "- Dataset management for reproducible experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79d8651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "from trulens.core.run import Run\n",
    "from trulens.core.run import RunConfig\n",
    "\n",
    "run_name = f\"health_queries_run_{uuid.uuid4()}\"\n",
    "\n",
    "run_config = RunConfig(\n",
    "    run_name=run_name,\n",
    "    dataset_name=\"health_research_queries\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    dataset_spec={\"RECORD_ROOT.INPUT\": \"query\"},\n",
    ")\n",
    "\n",
    "run: Run = tru_app.add_run(run_config=run_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea0738c",
   "metadata": {},
   "source": [
    "## Execute Batched Run\n",
    "\n",
    "Start the batched run to invoke the agent on all queries in the dataset. Each invocation will be traced and stored in Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ca933",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.start(input_df=queries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aae8f57",
   "metadata": {},
   "source": [
    "## Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000020f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "while run.get_status() != \"INVOCATION_COMPLETED\":\n",
    "    print(f\"Status: {run.get_status()}\")\n",
    "    time.sleep(3)\n",
    "\n",
    "print(\"Invocations complete, computing metrics...\")\n",
    "run.compute_metrics(metrics_to_compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ddede9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.get_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_intro",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Agent V2: Improved Tool Descriptions\n",
    "\n",
    "The base agent had two critical issues identified through TruLens evaluation:\n",
    "\n",
    "## Problems with Base Version\n",
    "\n",
    "**1. Poor Tool Selection (Score: Low)**\n",
    "- Agent didn't use tools for factual medical queries (e.g., \"What is Xeljanz indicated for?\")\n",
    "- Relied on internal knowledge instead of authoritative sources\n",
    "- Missed opportunities to verify medical information\n",
    "\n",
    "**2. Tool Calling Errors (Multiple Failures)**\n",
    "- Agent repeatedly tried to specify columns (`title`, `abstract`, `brief_description`, `disease_stage`)\n",
    "- These columns aren't indexed in Cortex Search, causing errors\n",
    "- No adaptation after errors - kept making the same mistakes\n",
    "- Example errors: `\"Column abstract was not indexed in this Cortex Search Service\"`\n",
    "\n",
    "## V2 Solution: Enhanced Tool Descriptions\n",
    "\n",
    "The V2 MCP server (`health_mcp_server_v2`) fixes these issues with improved tool descriptions:\n",
    "\n",
    "### Fix 1: Mandate Tool Usage\n",
    "- Tools marked as **\"AUTHORITATIVE\"** sources\n",
    "- Explicit **\"MANDATORY USE for\"** statements for specific query types\n",
    "- Lists exact use cases: drug indications, efficacy data, safety profiles, etc.\n",
    "\n",
    "### Fix 2: Prevent Column Specification Errors\n",
    "- Clear instruction: **\"Only provide 'query' parameter\"**\n",
    "- Agent will not specify columns to search that are not available\n",
    "\n",
    "### Expected Improvements\n",
    "- âœ… Higher Tool Selection scores (agent uses tools consistently)\n",
    "- âœ… Higher Tool Calling scores (no more column errors)\n",
    "\n",
    "## Setup Required\n",
    "\n",
    "Before running V2 cells, create the improved MCP server:\n",
    "```sql\n",
    "-- Run create_mcp_server_v2.sql in Snowflake\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_section",
   "metadata": {},
   "source": [
    "## Implementing Agent V2\n",
    "\n",
    "Now let's build and test the V2 agent with improved tool descriptions.\n",
    "\n",
    "**Prerequisites:** Ensure you've run `create_mcp_server_v2.sql` in Snowflake to create the `health_mcp_server_v2` MCP server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_client",
   "metadata": {},
   "source": [
    "## Create V2 Client with Improved MCP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_client_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the V2 MCP server\n",
    "os.environ[\"SNOWFLAKE_MCP_SERVER_V2_URL\"] = os.environ[\"SNOWFLAKE_MCP_SERVER_URL\"].replace(\n",
    "    \"health_mcp_server\", \"health_mcp_server_v2\"\n",
    ")\n",
    "\n",
    "client_v2 = MultiServerMCPClient({\n",
    "    \"health_research_v2\": {\n",
    "        \"transport\": \"streamable_http\",\n",
    "        \"url\": os.environ[\"SNOWFLAKE_MCP_SERVER_V2_URL\"],\n",
    "        \"headers\": {\"Authorization\": f\"Bearer {os.environ['SNOWFLAKE_PAT']}\"},\n",
    "    }\n",
    "})\n",
    "tools_v2 = await client_v2.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_agent",
   "metadata": {},
   "source": [
    "## Build Agent V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_agent_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model with V2 tools\n",
    "model_v2 = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "async def call_model_v2(state: MessagesState):\n",
    "    response = await model_v2.bind_tools(tools_v2).ainvoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "builder_v2 = StateGraph(MessagesState)\n",
    "builder_v2.add_node(call_model_v2)\n",
    "builder_v2.add_node(ToolNode(tools_v2))\n",
    "builder_v2.add_edge(START, \"call_model_v2\")\n",
    "builder_v2.add_conditional_edges(\"call_model_v2\", tools_condition)\n",
    "builder_v2.add_edge(\"tools\", \"call_model_v2\")\n",
    "graph_v2 = builder_v2.compile()\n",
    "\n",
    "agent_v2 = Agent(graph_v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_trugraph",
   "metadata": {},
   "source": [
    "## Wrap V2 Agent with TruGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_trugraph_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_app_v2 = TruGraph(\n",
    "    app=agent_v2,\n",
    "    app_name=\"healthcare_research_assistant-build-hol\",\n",
    "    app_version=\"v2_improved_descriptions\",\n",
    "    main_method=agent_v2.invoke,\n",
    "    connector=sf_connector,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_run",
   "metadata": {},
   "source": [
    "## Run V2 Agent on Same Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_run_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name_v2 = f\"health_queries_run_v2_{uuid.uuid4()}\"\n",
    "\n",
    "run_config_v2 = RunConfig(\n",
    "    run_name=run_name_v2,\n",
    "    dataset_name=\"health_research_queries\",\n",
    "    source_type=\"DATAFRAME\",\n",
    "    dataset_spec={\"RECORD_ROOT.INPUT\": \"query\"},\n",
    ")\n",
    "\n",
    "run_v2: Run = tru_app_v2.add_run(run_config=run_config_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_start",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_v2.start(input_df=queries_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v2_metrics",
   "metadata": {},
   "source": [
    "## Compute Metrics for V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1aa959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v2_metrics_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "while run_v2.get_status() != \"INVOCATION_COMPLETED\":\n",
    "    print(f\"V2 Status: {run_v2.get_status()}\")\n",
    "    time.sleep(3)\n",
    "\n",
    "print(\"V2 invocations complete, computing metrics...\")\n",
    "run_v2.compute_metrics(metrics_to_compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499bbaef",
   "metadata": {},
   "source": [
    "## Compare results\n",
    "\n",
    "By visiting the Comparison tab for Health Research Agent, we can compare how the agent performs with both versions of our MCP Server (before and after the tool description change).\n",
    "\n",
    "![agent_version_comparison.png](agent_version_comparison.png)\n",
    "\n",
    "By updating the tool descritions to mandate tool usage for specified use cases and specifying the search parameter, our agent is able to resolve the tool selection and tool calling failures from the first version of the agent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_mcp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
